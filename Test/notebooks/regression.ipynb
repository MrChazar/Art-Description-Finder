{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7f372f8a528511c6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T22:03:46.467686900Z",
     "start_time": "2024-05-22T22:03:46.443707200Z"
    }
   },
   "id": "9f26e4f2a0210687",
   "execution_count": 123
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of        IMDb_id                                                url None Mild  \\\n",
      "0    tt0111438  https://www.imdb.com/title/tt0111438/parentalg...    2   14   \n",
      "1    tt0349080  https://www.imdb.com/title/tt0349080/parentalg...    5    4   \n",
      "2    tt0088680  https://www.imdb.com/title/tt0088680/parentalg...   11   47   \n",
      "3    tt0066065  https://www.imdb.com/title/tt0066065/parentalg...    3    4   \n",
      "4    tt0065481  https://www.imdb.com/title/tt0065481/parentalg...    0    5   \n",
      "..         ...                                                ...  ...  ...   \n",
      "995  tt0112857  https://www.imdb.com/title/tt0112857/parentalg...    5   14   \n",
      "996  tt0091886  https://www.imdb.com/title/tt0091886/parentalg...    1    7   \n",
      "997  tt1228987  https://www.imdb.com/title/tt1228987/parentalg...   11   38   \n",
      "998  tt0239986  https://www.imdb.com/title/tt0239986/parentalg...    7    3   \n",
      "999  tt0068732  https://www.imdb.com/title/tt0068732/parentalg...    0   14   \n",
      "\n",
      "    Moderate Severe  \n",
      "0         20     17  \n",
      "1          6     59  \n",
      "2         50     15  \n",
      "3          0      0  \n",
      "4          6      0  \n",
      "..       ...    ...  \n",
      "995       15      2  \n",
      "996       10      6  \n",
      "997       15      6  \n",
      "998        0      8  \n",
      "999       13      3  \n",
      "\n",
      "[1000 rows x 6 columns]>\n",
      "Index(['IMDb_id', 'url', 'None', 'Mild', 'Moderate', 'Severe'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "file_name = \"nudity_train1000.pkl\"\n",
    "data = pd.read_pickle(f'training_pkl/{file_name}')\n",
    "print(data.head)\n",
    "print(data.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T22:03:46.771202400Z",
     "start_time": "2024-05-22T22:03:46.750010200Z"
    }
   },
   "id": "92b4c4a8ce1d8fb4",
   "execution_count": 124
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      tt0111438\n",
      "1      tt0349080\n",
      "2      tt0088680\n",
      "3      tt0066065\n",
      "4      tt0065481\n",
      "         ...    \n",
      "995    tt0112857\n",
      "996    tt0091886\n",
      "997    tt1228987\n",
      "998    tt0239986\n",
      "999    tt0068732\n",
      "Name: IMDb_id, Length: 1000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Pobranie kolumny 'IMDb_id' jako zmienna X\n",
    "X = data['IMDb_id']\n",
    "print(X)\n",
    "# Pobranie kolumn 'None', 'Mild', 'Moderate', 'Severe' jako zmienna y\n",
    "y = data[['None', 'Mild', 'Moderate', 'Severe']]\n",
    "y =  y.astype(float)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T22:03:47.126865Z",
     "start_time": "2024-05-22T22:03:47.081965100Z"
    }
   },
   "id": "fb9f048b3138e25a",
   "execution_count": 125
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T22:03:47.605221100Z",
     "start_time": "2024-05-22T22:03:47.401532100Z"
    }
   },
   "id": "f4dd8b4c15816d4b",
   "execution_count": 126
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "None        float64\nMild        float64\nModerate    float64\nSevere      float64\ndtype: object"
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "y_train.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T22:03:47.748330400Z",
     "start_time": "2024-05-22T22:03:47.704365400Z"
    }
   },
   "id": "d76c1a795d653e5c",
   "execution_count": 127
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X_train = [torch.tensor(tokenizer.encode(text)).float().unsqueeze(0) for text in X_train]\n",
    "X_test = [torch.tensor(tokenizer.encode(text)).float().unsqueeze(0) for text in X_test]\n",
    "y_train = [torch.tensor(y).float().unsqueeze(0) for y in y_train.values]\n",
    "y_test = [torch.tensor(y).float().unsqueeze(0) for y in y_test.values]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T22:03:48.311377100Z",
     "start_time": "2024-05-22T22:03:48.138881400Z"
    }
   },
   "id": "f4aead808dfad75a",
   "execution_count": 128
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 7])"
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].size()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T22:03:48.495276900Z",
     "start_time": "2024-05-22T22:03:48.430513600Z"
    }
   },
   "id": "9467600c815d836e",
   "execution_count": 129
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5])\n"
     ]
    }
   ],
   "source": [
    "embed_dim = len(X[0])\n",
    "m = nn.Linear(embed_dim, 5)\n",
    "input = torch.randn(1, embed_dim)\n",
    "output = m(input)\n",
    "print(output.size())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T22:03:48.813409Z",
     "start_time": "2024-05-22T22:03:48.792072400Z"
    }
   },
   "id": "760f039e33dd3043",
   "execution_count": 130
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#logistic regression\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T22:03:49.156618700Z",
     "start_time": "2024-05-22T22:03:49.135369200Z"
    }
   },
   "id": "f43fdd4110a98ca8",
   "execution_count": 131
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 7])"
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].size()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T22:03:49.622430700Z",
     "start_time": "2024-05-22T22:03:49.579128900Z"
    }
   },
   "id": "434bd24a259498e1",
   "execution_count": 132
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 4])"
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0].size()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T22:03:50.034157600Z",
     "start_time": "2024-05-22T22:03:50.008109500Z"
    }
   },
   "id": "fa78b7a77e6be5c1",
   "execution_count": 133
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#now build a model where input will be X_train[0] and output will be y_train[0]\n",
    "model = LinearRegression(7, 4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T22:03:50.380008300Z",
     "start_time": "2024-05-22T22:03:50.359535200Z"
    }
   },
   "id": "2fa3751a0ad27756",
   "execution_count": 134
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#loss function\n",
    "criterion = nn.MSELoss()\n",
    "#optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.000001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T22:03:50.758181500Z",
     "start_time": "2024-05-22T22:03:50.739821600Z"
    }
   },
   "id": "e11461f734338def",
   "execution_count": 135
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 7725.8228,  4486.2490,  3660.6348, -3169.0393]],\n       grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(X_train[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T22:03:51.238886900Z",
     "start_time": "2024-05-22T22:03:51.175435900Z"
    }
   },
   "id": "5ae8e49a775762a7",
   "execution_count": 136
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 25686316.0000\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x8 and 7x4)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[137], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(X_train)):\n\u001B[0;32m      5\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m----> 6\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m     loss \u001B[38;5;241m=\u001B[39m criterion(outputs, y_train[i])\n\u001B[0;32m      8\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[131], line 7\u001B[0m, in \u001B[0;36mLinearRegression.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m----> 7\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    115\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 116\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: mat1 and mat2 shapes cannot be multiplied (1x8 and 7x4)"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(len(X_train)):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train[i])\n",
    "        loss = criterion(outputs, y_train[i])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T22:03:51.630255900Z",
     "start_time": "2024-05-22T22:03:51.512229500Z"
    }
   },
   "id": "1958f70976fa8126",
   "execution_count": 137
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
