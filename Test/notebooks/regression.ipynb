{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7f372f8a528511c6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T04:12:14.662843Z",
     "start_time": "2024-05-23T04:12:01.442669Z"
    }
   },
   "id": "9f26e4f2a0210687",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of        IMDb_id                                                url None Mild  \\\n",
      "0    tt0111438  https://www.imdb.com/title/tt0111438/parentalg...    2   14   \n",
      "1    tt0349080  https://www.imdb.com/title/tt0349080/parentalg...    5    4   \n",
      "2    tt0088680  https://www.imdb.com/title/tt0088680/parentalg...   11   47   \n",
      "3    tt0066065  https://www.imdb.com/title/tt0066065/parentalg...    3    4   \n",
      "4    tt0065481  https://www.imdb.com/title/tt0065481/parentalg...    0    5   \n",
      "..         ...                                                ...  ...  ...   \n",
      "995  tt0112857  https://www.imdb.com/title/tt0112857/parentalg...    5   14   \n",
      "996  tt0091886  https://www.imdb.com/title/tt0091886/parentalg...    1    7   \n",
      "997  tt1228987  https://www.imdb.com/title/tt1228987/parentalg...   11   38   \n",
      "998  tt0239986  https://www.imdb.com/title/tt0239986/parentalg...    7    3   \n",
      "999  tt0068732  https://www.imdb.com/title/tt0068732/parentalg...    0   14   \n",
      "\n",
      "    Moderate Severe  \n",
      "0         20     17  \n",
      "1          6     59  \n",
      "2         50     15  \n",
      "3          0      0  \n",
      "4          6      0  \n",
      "..       ...    ...  \n",
      "995       15      2  \n",
      "996       10      6  \n",
      "997       15      6  \n",
      "998        0      8  \n",
      "999       13      3  \n",
      "\n",
      "[1000 rows x 6 columns]>\n",
      "Index(['IMDb_id', 'url', 'None', 'Mild', 'Moderate', 'Severe'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "file_name = \"nudity_train1000.pkl\"\n",
    "data = pd.read_pickle(f'training_pkl/{file_name}')\n",
    "print(data.head)\n",
    "print(data.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T04:12:14.725812Z",
     "start_time": "2024-05-23T04:12:14.667461Z"
    }
   },
   "id": "92b4c4a8ce1d8fb4",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "     IMDb_id                                                url None Mild  \\\n0  tt0111438  https://www.imdb.com/title/tt0111438/parentalg...    2   14   \n1  tt0349080  https://www.imdb.com/title/tt0349080/parentalg...    5    4   \n2  tt0088680  https://www.imdb.com/title/tt0088680/parentalg...   11   47   \n3  tt0066065  https://www.imdb.com/title/tt0066065/parentalg...    3    4   \n4  tt0065481  https://www.imdb.com/title/tt0065481/parentalg...    0    5   \n\n  Moderate Severe  \n0       20     17  \n1        6     59  \n2       50     15  \n3        0      0  \n4        6      0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>IMDb_id</th>\n      <th>url</th>\n      <th>None</th>\n      <th>Mild</th>\n      <th>Moderate</th>\n      <th>Severe</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>tt0111438</td>\n      <td>https://www.imdb.com/title/tt0111438/parentalg...</td>\n      <td>2</td>\n      <td>14</td>\n      <td>20</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>tt0349080</td>\n      <td>https://www.imdb.com/title/tt0349080/parentalg...</td>\n      <td>5</td>\n      <td>4</td>\n      <td>6</td>\n      <td>59</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>tt0088680</td>\n      <td>https://www.imdb.com/title/tt0088680/parentalg...</td>\n      <td>11</td>\n      <td>47</td>\n      <td>50</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>tt0066065</td>\n      <td>https://www.imdb.com/title/tt0066065/parentalg...</td>\n      <td>3</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>tt0065481</td>\n      <td>https://www.imdb.com/title/tt0065481/parentalg...</td>\n      <td>0</td>\n      <td>5</td>\n      <td>6</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T04:12:14.771725Z",
     "start_time": "2024-05-23T04:12:14.731226Z"
    }
   },
   "id": "5edfbdd9a8311615",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      tt0111438\n",
      "1      tt0349080\n",
      "2      tt0088680\n",
      "3      tt0066065\n",
      "4      tt0065481\n",
      "         ...    \n",
      "995    tt0112857\n",
      "996    tt0091886\n",
      "997    tt1228987\n",
      "998    tt0239986\n",
      "999    tt0068732\n",
      "Name: IMDb_id, Length: 1000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Pobranie kolumny 'IMDb_id' jako zmienna X\n",
    "X = data['IMDb_id']\n",
    "print(X)\n",
    "# Pobranie kolumn 'None', 'Mild', 'Moderate', 'Severe' jako zmienna y\n",
    "y = data[['None', 'Mild', 'Moderate', 'Severe']]\n",
    "y =  y.astype(float)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T04:12:21.088378Z",
     "start_time": "2024-05-23T04:12:21.066478Z"
    }
   },
   "id": "fb9f048b3138e25a",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "0      tt0111438\n1      tt0349080\n2      tt0088680\n3      tt0066065\n4      tt0065481\n         ...    \n995    tt0112857\n996    tt0091886\n997    tt1228987\n998    tt0239986\n999    tt0068732\nName: IMDb_id, Length: 1000, dtype: object"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T04:12:23.712843Z",
     "start_time": "2024-05-23T04:12:23.692382Z"
    }
   },
   "id": "485e3cc3befa784d",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T04:15:44.639704Z",
     "start_time": "2024-05-23T04:15:44.341455Z"
    }
   },
   "id": "f4dd8b4c15816d4b",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "None        float64\nMild        float64\nModerate    float64\nSevere      float64\ndtype: object"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "y_train.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T05:10:31.300675Z",
     "start_time": "2024-05-23T05:10:31.275990Z"
    }
   },
   "id": "d76c1a795d653e5c",
   "execution_count": 89
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "y_train = [torch.tensor(y).float().unsqueeze(0) for y in y_train.values]\n",
    "y_test = [torch.tensor(y).float().unsqueeze(0) for y in y_test.values]\n",
    "#now get first 7 elements of each tensor in X_train and X_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T06:13:56.786397Z",
     "start_time": "2024-05-23T06:13:56.764810Z"
    }
   },
   "id": "f4aead808dfad75a",
   "execution_count": 139
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1f07299e993f45fca918d55c899889a0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dimas\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\dimas\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "398403adcbc7430eba430104f5d837b7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "09d13092ffbb47adb2d4c377de27ee6a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dc06c12a849241608d697d3e3e1d4a82"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T04:54:20.754558Z",
     "start_time": "2024-05-23T04:54:17.738637Z"
    }
   },
   "id": "760f039e33dd3043",
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "text = \"Here is the sentence I want embeddings for.\"\n",
    "tokenized_text = tokenizer.encode_plus(text, add_special_tokens=True, return_tensors='pt')\n",
    "X_train = [tokenizer.encode_plus(text, add_special_tokens=True, return_tensors='pt') for text in X_train]\n",
    "X_test = [tokenizer.encode_plus(text, add_special_tokens=True, return_tensors='pt') for text in X_test]\n",
    "input_ids_train = [x['input_ids'] for x in X_train]\n",
    "input_ids_test = [x['input_ids'] for x in X_test]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T05:10:35.539857Z",
     "start_time": "2024-05-23T05:10:35.173733Z"
    }
   },
   "id": "cbbc79e5fe42ab4c",
   "execution_count": 90
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "attention_mask_train = [x['attention_mask'] for x in X_train]\n",
    "attention_mask_test = [x['attention_mask'] for x in X_test]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T05:10:49.581849Z",
     "start_time": "2024-05-23T05:10:49.568393Z"
    }
   },
   "id": "a900e0b8823de6ac",
   "execution_count": 91
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\n",
      "Criterion\n",
      "Optimizer\n",
      "Forward pass\n"
     ]
    }
   ],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('prajjwal1/bert-tiny')\n",
    "        self.linear = nn.Linear(input_dim, 4)\n",
    "    def forward(self, i):\n",
    "        outputs = self.bert(input_ids=input_ids_train[i], attention_mask=attention_mask_train[i]).last_hidden_state \n",
    "        # Take the mean of the sequence_length dimension\n",
    "        out = self.linear(outputs)\n",
    "        out = out.mean(dim=1)\n",
    "        return out\n",
    "\n",
    "model = LinearRegression(128, 4)\n",
    "print('Model')\n",
    "# Loss function\n",
    "criterion = nn.MSELoss()\n",
    "print('Criterion')\n",
    "# Optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0000001)\n",
    "print('Optimizer')\n",
    "# Forward pass\n",
    "o = model.forward(1)\n",
    "print('Forward pass')\n",
    "criteria = criterion(o, y_train[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T06:14:05.110880Z",
     "start_time": "2024-05-23T06:14:04.755334Z"
    }
   },
   "id": "f43fdd4110a98ca8",
   "execution_count": 141
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not BatchEncoding",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[142], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_epochs):\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(X_train)):\n\u001B[1;32m----> 5\u001B[0m         output \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m         loss \u001B[38;5;241m=\u001B[39m criterion(output, y_train[i])\n\u001B[0;32m      8\u001B[0m         loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "Cell \u001B[1;32mIn[141], line 7\u001B[0m, in \u001B[0;36mLinearRegression.forward\u001B[1;34m(self, i)\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, i):\n\u001B[1;32m----> 7\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbert(input_ids\u001B[38;5;241m=\u001B[39m\u001B[43minput_ids_train\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m, attention_mask\u001B[38;5;241m=\u001B[39mattention_mask_train[i])\u001B[38;5;241m.\u001B[39mlast_hidden_state \n\u001B[0;32m      8\u001B[0m     \u001B[38;5;66;03m# Take the mean of the sequence_length dimension\u001B[39;00m\n\u001B[0;32m      9\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlinear(outputs)\n",
      "\u001B[1;31mTypeError\u001B[0m: list indices must be integers or slices, not BatchEncoding"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(len(X_train)):\n",
    "        output = model.forward(X_train[i])\n",
    "        loss = criterion(output, y_train[i])\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T06:14:46.143512Z",
     "start_time": "2024-05-23T06:14:46.089777Z"
    }
   },
   "id": "1958f70976fa8126",
   "execution_count": 142
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9df8250d11d712ee"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
